input {
    kafka {
        bootstrap_servers => "{{ kafka_ms_node_name }}"
        codec => "json"
        consumer_threads => 12
        session_timeout_ms => "300000"
        #fetch_max_wait_ms => "4000"
        #request_timeout_ms => "5000"
        retry_backoff_ms => "1000"
        topics => ["logging.event_log"]
        auto_offset_reset => "earliest"
        type => "audit-log"
        decorate_events => true
        id => "logging-event-log-in"
    }
}
filter {
    fingerprint {
        target => "[@metadata][uuid]"
        method => "SHA1"
        concatenate_all_fields => true
    }
    if (![EVENT_CODE]) {
        mutate {
            add_tag => [ "none_event_code" ]
        }
    }
    date {
        match => [ "TIMESTAMP", "yyyy-MM-dd'T'HH:mm:ss.SSSZ" ]
    }
    ruby {
        code => "event.set('[@metadata][localtime]', event.get('@timestamp').time.localtime('+07:00').strftime('%Y.%m.%d'))"
    }
}
output {
    if "none_event_code" in [tags] {
        file {
            path => "{{ logstash_path_final }}/grok-failure-%{[@metadata][localtime]}.log"
            codec => rubydebug
        }
    } else {
        elasticsearch {
            hosts => {{ audit_log_index }}
            user => "{{ conf_d_es_user }}"
            password => "{{ conf_d_es_password }}"
            timeout => 60
            ssl => true
            cacert => '{{ logstash_cert_path }}/trusted-cert/{{ rootca }}'
            manage_template => false
            index => "audit-%{[@metadata][localtime]}"
            document_type => "audit"
            document_id => "%{[@metadata][uuid]}"
        }
    }
    #stdout { codec => rubydebug }
}